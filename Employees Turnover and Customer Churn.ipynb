{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a971f04",
   "metadata": {},
   "source": [
    "# Employees Turnover Overview\n",
    "\n",
    "The Employees Dataset:\n",
    "\n",
    "الداتا ب :\n",
    "HR_comma_sep.csv\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/how-to-build-a-deep-learning-model-to-predict-employee-retention-using-keras-and-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a77eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee Turnover ML Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "feats = [\"department\", 'salary']\n",
    "df_final = pd.get_dummies (df, columns=feats,drop_first=True)\n",
    "X = df_final.drop (['left '],axis=1).values\n",
    "y = df_final['left'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "rf = RandomForestClassifier ()\n",
    "rf.fit (X_train, y_train)\n",
    "lr = LogisticRegression ()\n",
    "lr.fit(X_train, y_train)\n",
    "svc_w_1inear_kernel = SVC (kernel='linear')\n",
    "svc_w_linear_kernel.fit(X_train, y_train)\n",
    "svc_wo_linear_kernel = SVC ()\n",
    "svc_wo_linear_kernel.fit(X_train,y-train)\n",
    "c1f = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print ('Random Forest Classifier accuracy:',rf.score (X_test, y_test))\n",
    "print('Logistic Regression accuracy: ',Ir. score(X_test, y_test))\n",
    "print( 'SVC_w_linear_kernel accuracy: ' ,svc_w_linear_kernel.score(X_test,y_test))\n",
    "print( 'SVC wo linear kernel accuracy: ' ,svc_wo_linear_kernel.score(X_test,y_test))\n",
    "print( 'KNeighborsClassifier accuracy: ', clf.score(X_test, y_test))\n",
    "example_measures = np.array([[0.26,0.7 , 3., 238., 6., 0.,0.,0.,0., 0.,0.,0.,0.,0.,1.,0., 0., 1. ]])\n",
    "prediction = svc_wo_linear_kernel.predict(example_measures)\n",
    "new_pred = (prediction > 0.5)\n",
    "print(\" SVC_wo_linear_kernel new_pred :\", new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee Turnover DL Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras. layers import Dropout\n",
    "df = pd.read_csv (\"HR_comma_sep.csv\")\n",
    "feats = ['department', 'salary']\n",
    "df_final = pd.get_dummies (df, columns=feats, drop_first=True)\n",
    "x = df_final.drop™['left'],axis=1). values\n",
    "y = df_final['left'].values\n",
    "X_train, X_test, _train, _test = train_test_split(X, y, test_size=0.3)\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "classifier = Sequential ()\n",
    "classifiere.add(Dense(9, kernel_initializer = \"uniform\", activation = \"relu\", input_dim=18))\n",
    "classifiero.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\"‚activatiog = \"sigmoid\"))\n",
    "classifiere.compile (optimizer= \"adam\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "classifiere.fit(X_train, y_train, batch_size = 10, epochs = 5)\n",
    "y_pred = classifiero.predict (X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(\"y_pred : \"›y_pred)\n",
    "cm = confusion_matrix (y_test, y_pred)\n",
    "print(\"cm :\", cm)\n",
    "scores = classifier.evaluate (X_test, _test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (classifier0.metrics_names [1], scores [1]*100))\n",
    "new_pred = classifier0.predict(sc.transform(np.array([[0.26,0.7 ,3., 238., 6., 0.,0., 0., 0., 0.,0.,0.,0.,0.,1.,0., 0., 1.]])\n",
    "new_pred = (new_pred > 0.5)\n",
    "print (\"new_pred :\", new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e6f7d",
   "metadata": {},
   "source": [
    "# Customer Churn Overview\n",
    "\n",
    "Bank Customer Churn Dataset:\n",
    "\n",
    "الداتا ب:\n",
    "https://www.kaggle.com/aakash50897/churn-modellingcsv\n",
    "\n",
    "https://towardsdatascience.com/building-your-own-artificial-neural-network-from-scratch-on-churn-modeling-dataset-using-keras-in-690782f7d051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fec010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank Customer Churn ML Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Labelencoder, OneHotEncoder, standardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = pd.read_csv ('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13]. values\n",
    "labelencoder_X _1 = LabelEncoder ()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder X 2 = LabelEncoder ()\n",
    "X[:, 2] = labelencoder _X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder (categorical_features = [1])\n",
    "X = onehotencoder. fit_transform(X) . toarray ()\n",
    "X = X[:, 1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc. transform(X test)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "Ir = LogisticRegression()\n",
    "Ir.fit(X_train, y_train)\n",
    "svc_w_linear_kernel = SVC (kernel='linear')\n",
    "svc_w_linear_kernel.fit (X_train, y_train)\n",
    "svc_wo_linear_kernel = SVC ()\n",
    "svc_wo_linear_kernel.fit(X_train, y_train)\n",
    "clf = neighbors.KNeighborsClassifier ()\n",
    "print( 'Random Forest Classifier accuracy:',rf.score(X_test, y_test))\n",
    "print('Logistic Regression accuracy:',r.score (X_test, y_test))\n",
    "print( 'SVC w linear kernel accuracy: ', svc_W_linear_kernel. score(X test, y test))\n",
    "print( 'SVC_wo_linear_kernel accuracy: ',svc_wo_linear_kernel.score(X_test, y_test))\n",
    "print( 'KNeighborsClassifier accuracy:' ,clf.score(X_test, y_test))\n",
    "example_measures = np.array ([[0.0,0.0 ,3.0,0.0, 7.0, 2.0,0.1,0.1,0.0, 0.0,1.0]])\n",
    "prediction = svc_wo_linear_kernel.predict(example_measures)\n",
    "new_pred = (prediction > 0.5)\n",
    "print(\" \\nSVC_wo_linear _kernel new_pred :\", new_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c50c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank Customer Churn DL Example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, standardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dataset = pd. read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc [:, 13]. values\n",
    "print (X)\n",
    "print (y)\n",
    "labelencoder_X_1 = LabelEncoder ()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder ()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder (categorical_ features = [1])\n",
    "X = onehotencoder. fit_transform(X) . toarray ()\n",
    "X = X[:, 1:]\n",
    "X_train, X_test, _train, _test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler ()\n",
    "X train = sc.fit transform(X train)\n",
    "X_test = sc.transform(X _test)\n",
    "classifier = Sequential ()\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 50)\n",
    "y_pred = classifier.predict (X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "Result = list (y_pred)\n",
    "print(\"True Count\" , Result. count (True))\n",
    "print(\"False Count \", Result.count (False))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (cm)\n",
    "#print(accuracy)\n",
    "accuracy = classifier.evaluate(×=X_test,y=y_test, batch_size=10)\n",
    "print(\"Accuracy: \", accuracy[1])\n",
    "classifier.save(\"Churn_Bank_model.h5\")\n",
    "new_pred = classifier.predict(sc.transform(np.array[[0.0,0.0 ,3.0,0.0, 7.0, 2.0,0.1,0.1,0.0, 0.0,1.01]]))\n",
    "new_pred = (new_pred > 0.5)\n",
    "print(\"new pred: \", new _pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f5d22",
   "metadata": {},
   "source": [
    "# Teleco Customer Churn\n",
    "\n",
    "Teleco Customer Churn Dataset:\n",
    "\n",
    "الداتا ب:\n",
    "https://www.kaggle.com/blastchar/telco-customer-churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = pd.read_Csv('WA_Fn-UseC_-Telco-Customer-Caurn.csv')\n",
    "Teleco_Data = dataset.iloc[:, 1:20].values\n",
    "Teleco_Lables = dataset.iloc [:, 20].values\n",
    "print(\"original:\", Teleco_Data[0, 0:20],\" -›Count\", len (Teleco_Data[0, 0:20]))\n",
    "labelencoder Teleco Data = LabelEncoder ()\n",
    "#Teleco_Data[:, 0] = labelencoder_Teleco_Data.fit_transform(Teleco_Data[:, 0])\n",
    "for col,i in enumerate (Teleco_Data[0,0:19]):\n",
    "    if type(i) is str:\n",
    "        Teleco_Data[:, col] = labelencoder_Teleco_Data.fit_transform(Teleco_Data[:, col])\n",
    "print (\"encoder: \", Teleco_Data[0,0:20], ,\" -›Count\", len (Teleco_Data[0, 0:20]))\n",
    "print( \"encoder:\" , Teleco_Data [1, 0:20],\" -›Count\", len (Teleco_Data [1,0:20]))\n",
    "print (\"encoder:\", Teleco_Data [1,0:20],\" -›Count\", len (Teleco_Data[1,0:20]))\n",
    "Teleco_Lables[:] = labelencoder_Teleco_Data.fit_transform(Teleco_Lables [:])\n",
    "X_train, X_test, _train, _test = train_test_split(Teleco_Data, Teleco_Lables, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit transform(X train)\n",
    "X_test = sc.transform(X test)\n",
    "classifier_model = Sequential ()\n",
    "classifier_model.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu', input_dim = 19))\n",
    "classifier_model.add (Dense(output_dim = 10, init = 'uniform', activation = 'relu'))\n",
    "classifier_model.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "classifier_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier_model.fit(X_train, y_train, batch_size = 35, nb_epoch = 50)\n",
    "y_pred = classifier_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "Result = list (y_pred)\n",
    "print (\"True Count :\", Result.count (1))\n",
    "print (\"False Count :\", Result.count (0))\n",
    "loss, accuracy = classifier_model.evaluate (x=X_test,y=y_test, verbose=0)\n",
    "print('InTesting loss: {}, accuracy: (}\\n'.format (loss, accuracy))\n",
    "classifier_model.save(\"Churn_Teleco_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
