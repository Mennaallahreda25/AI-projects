{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc86ea05",
   "metadata": {},
   "source": [
    "**Downloading the Models**\n",
    "\n",
    "-age_deploy.prototxt: Age discrimination network configuration file \n",
    "\n",
    "-age_net.caffemodel: Model file for age discrimination network \n",
    "\n",
    "-gender_deploy.prototxt: Gender discrimination network configuration file \n",
    "\n",
    "-gender_net.caffemodel: Model file of the gender discrimination network \n",
    "\n",
    "-opencv_face_detector. pbtxt: Profile of the face recognition network \n",
    "\n",
    "-opencv_face_detector_uint8.pb: a model file for a face recognition network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d2ea6",
   "metadata": {},
   "source": [
    "# Predict Age and Gender from Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c6db6",
   "metadata": {},
   "source": [
    "**Predict Age and Gender from Camera needed data:**\n",
    "    \n",
    "this link have file (haarcascade frontaltace alt.xml):\n",
    "https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "this link have files (deploy_age.prototxt , deploy_gender.prototxt):\n",
    "https://github.com/natanielruiz/net-archive/tree/master/age-gender\n",
    "\n",
    "this link have files (age_net.caffemodel , gender_net.caffemodel):\n",
    "https://github.com/eveningglow/age-and-gender-classification/tree/master/model\n",
    "\n",
    "this link have file (Gender-and-Age-Detection-OpenCV-Caffe/predict.py):\n",
    "https://github.com/raunaqness/Gender-and-Age-Detection-OpenCV-Caffe/blob/master/predict.py \n",
    "\n",
    "and first we need to install openCv:\n",
    "pip install OpenCV-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a993996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Age and Gender from Camera\n",
    "import cv2\n",
    "cap = cv2.VideoCapture (0)\n",
    "cap.set (3, 480) #set width\n",
    "cap.set (4, 640) #set height\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "def initialize_caffe_models ():\n",
    "    age_net = cv2. dnn. readNetFromCaffe('deploy_age.prototxt','age_net.caffemodel')\n",
    "\n",
    "    gender_net = cv2.dnn. readNetFromCaffe('deploy_gender .prototxt','gender net.caffemodel')\n",
    "\n",
    "    return(age_net, gender_net)\n",
    "\n",
    "def read_from_camera(age_net, gender_net):\n",
    "    font = cv2. FONT_HERSHEY_SIMPLEX\n",
    "    while True:\n",
    "        ret, image = cap. read()\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "        gray = cv2.cvtColor (image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade. detectMultiScale (gray, 1.1, 5)\n",
    "        if(len (faces)>0):\n",
    "            print(\"Found {} faces\".format(str (len(faces))))\n",
    "        for (x, y, w, h )in faces:\n",
    "            cv2. rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "            # Get race\n",
    "            face_img = image [y:yth, h:h+w].copy ()\n",
    "            blob = cv2.dnn.blobFromImage (face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "            \n",
    "            #Predict Gender \n",
    "            gender_net.setInput (blob)\n",
    "            gender_preds = gender_net.forward()\n",
    "            gender = gender_list[gender_preds [0].argmax()]\n",
    "            print(\"Gender :\"+ gender)\n",
    "            #Predict Age \n",
    "            age_net.setInput (blob)\n",
    "            age_preds = age_net.forward()\n",
    "            age = age_list[age_preds [0].argmax()]\n",
    "            print (\"Age Range:\"+ age)\n",
    "            overlay text = \"%s %s\" % (gender, age)\n",
    "            cv2. putText (image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2. LINE_AA)\n",
    "        cv2.imshow ('frame' image)\n",
    "        if cv2.waitKey (1) & OxFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "if _name_== \"_main_\":\n",
    "    age_net, gender_net = initialize_caffe_models()\n",
    "    read_from_camera (age_net, gender_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28657",
   "metadata": {},
   "source": [
    "# Predict Age and Gender from Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a828845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Age and Gender from Picture\n",
    "import cv2\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_list = ['(0, 2)'.\n",
    "'(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)','(48, 53)','(60, 100) ']\n",
    "gender_list = ['Male','Female']\n",
    "def initialize_caffe_models ():\n",
    "    age_net = cv2. dnn. readNetFromCaffe('deploy_age.prototxt','age_net.caffemodel')\n",
    "\n",
    "    gender_net = cv2.dnn. readNetFromCaffe('deploy_gender .prototxt','gender net.caffemodel')\n",
    "\n",
    "    return(age_net, gender_net)\n",
    "\n",
    "def read_from_image(age_net, gender_net):\n",
    "    font = cv2. FONT_HERSHEY_SIMPLEX\n",
    "    image = cv2. imread(\"faces13.jpg\")\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    gray = cv2.cvtColor (image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade. detectMultiScale (gray, 1.1, 5)\n",
    "    if(len (faces)>0):\n",
    "        print(\"Found {} faces\".format(str (len(faces))))\n",
    "\n",
    "    for (x, y, w, h )in faces:\n",
    "                cv2. rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "                # Get race\n",
    "                face_img = image [y:yth, h:h+w].copy ()\n",
    "                blob = cv2.dnn.blobFromImage (face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "                #Predict Gender \n",
    "                gender_net.setInput (blob)\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds [0].argmax()]\n",
    "                print(\"Gender :\"+ gender)\n",
    "                #Predict Age \n",
    "                age_net.setInput (blob)\n",
    "                age_preds = age_net.forward()\n",
    "                age = age_list[age_preds [0].argmax()]\n",
    "                print (\"Age Range:\"+ age)\n",
    "                overlay text = \"%s %s\" % (gender, age)\n",
    "                cv2. putText (image, overlay_text, (x, y), font, .5, (100, 100, 255), 2, cv2. LINE_AA)\n",
    "            cv2.imshow(\"\" ,image)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "if _name_== \"_main_\":\n",
    "    age_net, gender_net = initialize_caffe_models()\n",
    "    read_from_image (age_net, gender_net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56979d0",
   "metadata": {},
   "source": [
    "# Predict Age and Gender from YouTube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fa9ce",
   "metadata": {},
   "source": [
    "**Predict Age and Gender from YouTube Video needed data:**\n",
    "\n",
    "this link have file (haarcascade frontaltace alt.xml): \n",
    "https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "this link have files (deploy_age.prototxt , deploy_gender.prototxt):\n",
    "https://github.com/natanielruiz/net-archive/tree/master/age-gender\n",
    "\n",
    "this link have files (age_net.caffemodel , gender_net.caffemodel): \n",
    "https://github.com/eveningglow/age-and-gender-classification/tree/master/model\n",
    "\n",
    "source code:\n",
    "https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html\n",
    "    \n",
    "and first we need to install:\n",
    "- pip install youtube-di \n",
    "- pip install pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Age and Gender from YouTube Video\n",
    "import cv2\n",
    "import pafy\n",
    "#url of the video to predict Age and gender\n",
    "url = 'https://www.youtube.com/watch?v=iH1ZJVqJ03Y'\n",
    "vPafy = pafy.new (url)\n",
    "play = VPafy.getbest(preftype=\"mp4\")\n",
    "cap = cv2.VideoCapture (play.ur1)\n",
    "cap. set (3, 480) #set width of the frame\n",
    "cap. set (4, 640) #set height of the frame\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_list = ['(0, 2)','(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', ' (48. 53)', '(60, 100) ']\n",
    "gender_list = ['Male', 'Female']\n",
    "def load_caffe_models () :\n",
    "    age_net = cv2.dnn. readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n",
    "    gender_net = cv2.dnn. readNetFromCaffe('deploy_gender prototxt', 'gender_net.caffemodel')\n",
    "    return(age_net, gender_net)\n",
    "def video_detector (age_net, gender_net):\n",
    "    font = _cv2.FONT_HERSHEY_SIMPLEX\n",
    "    while True:\n",
    "        ret, image = cap.read ()\n",
    "        face_cascade = cv2. Cascadeclassifier('haarcascade_frontalface_alt.xml')\n",
    "        gray = cv2. cvtColor (image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade. detectMultiScale (gray, 1.1, 5)\n",
    "        if(len(faces)>0):\n",
    "            print(\"Found {} faces\".format(str (len(faces))))\n",
    "        for (x, y, W, h )in faces:\n",
    "            cv2.rectangle (image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "            #Get Face\n",
    "            face_img = image[y:y+h, h:h+w].copy ()\n",
    "            blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES,swapRB=False)\n",
    "            #predict Gender\n",
    "            gender_net.setInput (blob)\n",
    "            gender_preds = gender_net. forward()\n",
    "            gender gender_list[gender_preds[0].argmax()]\n",
    "            print(\"Gender + gender)\n",
    "            #Predict Age \n",
    "            age_net.setInput (blob)\n",
    "            age_preds = age_net.forward()\n",
    "            age = age_list[age_preds [0].argmax()]\n",
    "            print (\"Age Range:\" + age)\n",
    "            overlay_text = \"%s %s\" % (gender, age)\n",
    "            cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2. LINE_AA)\n",
    "            cv2. imshow ('frame',image)\n",
    "            #OXFF is a hexadecimal constant which is 11111111 in binary.\n",
    "            waitKey (1) & OxFF == ord('q'):\n",
    "\n",
    "if _name_== \"_main_\":\n",
    "    age_net, gender_net = initialize_caffe_models()\n",
    "    video_detector (age_net, gender_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968aa39e",
   "metadata": {},
   "source": [
    "# Predict Age and Gender from Camera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e1dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T22:14:41.265999Z",
     "start_time": "2023-04-03T22:14:41.185184Z"
    }
   },
   "source": [
    "**Predict Age and Gender from Camera needed data:**\n",
    "\n",
    "-age_deploy.prototxt: Age discrimination network configuration file \n",
    "\n",
    "-age_net.caffemodel: Model file for age discrimination network \n",
    "\n",
    "-gender_deploy.prototxt: Gender discrimination network configuration file \n",
    "\n",
    "-gender_net.caffemodel: Model file of the gender discrimination network \n",
    "\n",
    "-opencv_face_detector. pbtxt: Profile of the face recognition network \n",
    "\n",
    "-opencv_face_detector_uint8.pb: a model file for a face recognition network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Age and Gender from Camera\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy ()\n",
    "    frameHeight=frameOpencDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "    net.setInput (blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range (detections.shape [2]):\n",
    "        confidence=detections [0,0, i,2] \n",
    "        if confidence>conf_threshold:\n",
    "            ×1=int (detections [0,0, i, 3]*framewidth) \n",
    "            y1=int (detections [0,0, i,4]*frameHeight)\n",
    "            X2=int (detections [0,0,1,5]*frameWidth) \n",
    "            y2=int (detections [0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1, ×2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,1), (x2,y2), (0,255,0), int (round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, faceBoxes\n",
    "parser=argparse. ArgumentParser ()\n",
    "parser. add_argument ('--image')\n",
    "args=parser.parse_args ()\n",
    "faceProto=\"opencv_face_detector.pbtxt\"\n",
    "faceModel=\"opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"age_deploy.prototxt\"\n",
    "ageModel=\"age_net. caffemodel\"\n",
    "genderProto=\"gender_deploy.prototxt\"\n",
    "genderModel=\"gender_net.caffemodel\"\n",
    "MODEL_MEAN_VALUES= (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "age_list = ['(0, 2)','(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', ' (48. 53)', '(60, 100) ']\n",
    "genderList= ['Male','Female ']\n",
    "faceNet=cv2.dnn. readNet (faceModel, faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2. dnn. readNet (genderModel, genderProto)\n",
    "video=cv2.VideoCapture (args.image if args.image else 0)\n",
    "padding=20\n",
    "while cv2.waitKey (1)<0:\n",
    "             hasFrame, frame=video.read ()\\\n",
    "             if not hasFrame:\n",
    "                 cv2.waitKey ()\n",
    "                 break\n",
    "             \n",
    "            resultImg, faceBoxes=highlightFace(faceNet, frame)\n",
    "            if not faceboxes:\n",
    "                print(\"No face detected\")\n",
    "            for faceBox in FaceBoxes:\n",
    "                face=frame [max(0, faceBox [1]-padding) :\n",
    "                min(faceBox[3]+padding, frame.shape [0]-1),max(0, faceBox[0]-padding)\n",
    "                :min(faceBox[2]+padding, frame. shape [1]-1)]\n",
    "\n",
    "                blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False) \n",
    "                genderNet.setInput (blob) \n",
    "                genderPreds=genderNet. forward() \n",
    "                gender=genderList[genderPreds [0].argmax ()] \n",
    "                print (f'Gender: {gender}')\n",
    "                ageNet. setInput (blob) \n",
    "                agePreds=ageNet.forward()\n",
    "                age=ageList[agePreds[0].argmax()] \n",
    "                print (f'Age: (age[1:-1]) years')\n",
    "                cv2.putText (resultImg, f'(gender), (age)', (faceBox [0], faceBox[1]-10),cV2. FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2. LINE_AA)\n",
    "                cv2. imshow (\"Detecting age and gender\" , resultImg)\n",
    "            \n",
    "             \n",
    "\n",
    "# to run the code choose image then write>>\n",
    "C:\\Python\\Mystuff>python AgeGender.py --input sample1.jpg\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a803c",
   "metadata": {},
   "source": [
    "# Predict Age and Gender from picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Age and Gender from picture 2\n",
    "import cv2 as cv\n",
    "import time\n",
    "import argparse\n",
    "def getFaceBox(net, frame, conf_threshold=0.7) :\n",
    "    frameOpencvDn = frame. copy ()\n",
    "    frameleight = frameOpencDnn. shape [0]\n",
    "    frameWidth = frameOpencvDnn. shape [1]\n",
    "    blob = cv.dnn.blobFromImage (frameOpencvDnn, 1.0, (300, 300), [104, 117, 123],True, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward ()\n",
    "    bboxes = []\n",
    "    for i in range (detections. shape [2]):\n",
    "        confidence = detections [0, 0, i, 2]\n",
    "        if confidence > conf threshold:\n",
    "            x1 = in(detections[0, 0, i, 3]* frameWidth)\n",
    "            y1 = int (detections[0, 0, i, 4]*frameHeight)\n",
    "            ×2 = int(detections[0, 0, i, 5]* frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6]*frameHeight)\n",
    "\n",
    "            bboxes.append([x1, y1, X2, y2])\n",
    "            cv.rectangle(frameOpencDnn, (x1, y1), (X2, y2), (0, 255, 0),int(round(frameHeight/150)), 8)\n",
    "    return frameOpencDnn, bboxes\n",
    "parser = argparse. ArgumentParser (description='Use this script to run age and gender recognition using OpenCV.')\n",
    "parser. add_argument (\"--input',help='Path to input image or video file. Skip this argument to capture frames from a camera.\")\n",
    "args = parser.parse_args ()\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "genderProto = \"gender_deploy-prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)    \n",
    "age_list = ['(0, 2)','(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', ' (48. 53)', '(60, 100) ']\n",
    "genderList= ['Male','Female']    \n",
    "\n",
    "# Load network\n",
    "ageNet = cv.dnn. readNet (ageModel, ageProto)\n",
    "genderNet = cv.dnn. readNet (genderModel, genderProto)\n",
    "faceNet = cv.ann. readNet faceModel, faceProto)\n",
    "# Open a video file or an mage file or a camera strean\n",
    "cap = cv. VideoCapture (args.input if args.input else 0)\n",
    "padding = 20\n",
    "while cv.waitKey (1) ‹ 0:\n",
    "    t = time.time ()\n",
    "    hasFrame,frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        cv.waitkey ()\n",
    "        break\n",
    "\n",
    "    frameFace, bboxes = getFaceBox (faceNet, frame)\n",
    "    if not bboxes:\n",
    "        print(\"No face Detected, Checking next frame\")\n",
    "        continue\n",
    "    for bbox in boxes:\n",
    "\n",
    "        face = frame [max(0, bbox[1]-padding):min(bbox[3]+padding, frame.shape [0]-1),max(0, bbox[0]-padding) :min(bbox[2]+padding, frame. shape[1]-1)]\n",
    "        blob = cv.dnn.blobFromImage (face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet. setInput (blob)\n",
    "        genderPreds = genderNet. forward()\n",
    "        gender = genderList[genderPreds [0] .argmax ()]\n",
    "        # print\"Gender Output : ‹\".format (genderPreds))\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format (gender, genderPreds [0].max()))\n",
    "        ageNet.setInput (blob)\n",
    "        agePreds = ageNet.forward ()\n",
    "        age = ageList [agePreds [0].argmax ()]\n",
    "        print (\"Age Output :{}\".format (agePreds))\n",
    "        print (\"Age :{} , conf= {:.3f}\". format (age, agePreds [0].max ()))\n",
    "        label=\"{},{}\".format (gender, age)\n",
    "        cv.putText (frameFace, label, (bbox [0], bbox[1]-10), cv. FONT_HERSHEY_SIMPLEX,0.8,(0,255,255), 2, cV. LINE_AA)\n",
    "        cv.imshow( \"Age Gender Demo\" , tramerace)\n",
    "    # cv. imwrite( \"age-gender-out-{}\".format(args. input), frameFace)\n",
    "    print(\"time : {:.3f}\".format(time.time () - t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc197a",
   "metadata": {},
   "source": [
    "**to use the ready model will find in this link :**\n",
    "https://github.com/spmallick/learnopencv/tree/master/AgeGender\n",
    "    \n",
    "you can use by this way :\n",
    "C: \\Python \\Mystuff>python AgeGender.py --input sample1.jpg\n",
    "\n",
    "or we can aelse try to modify in the source code to make in better accuracy if we want\n",
    "- and we will find all files we used too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56276ff2",
   "metadata": {},
   "source": [
    "# refrences:\n",
    "\n",
    "https://data-flair.training/blogs/python-project-gender-age-detection/\n",
    "\n",
    "https://github.com/spmallick/learnopencv/tree/master/AgeGender\n",
    "\n",
    "https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6\n",
    "\n",
    "https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609b2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
