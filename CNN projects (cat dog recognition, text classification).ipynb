{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553809e8",
   "metadata": {},
   "source": [
    "# CNN project 1: Cat Dog Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras Libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras. layers import MaxPooling2D\n",
    "from keras. layers import Flatten\n",
    "from keras.layers import Dense\n",
    "# Initialising the CNN\n",
    "classifier = Sequential ()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3),activation = 'relu'))\n",
    "# Filters 32- Filter's shape -64Ã—64 resolution and \"3\" stands for RGB\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D (pool_size = (2, 2))) # 2x2 matrix\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense (units = 128, activation = 'relu')) # number of nodes\n",
    "classifier.add(Dense(units = 1, activation ='sigmoid'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen= ImageDataGenerator (rescale = 1./255, shear_range = 0.2,zoom_range= 0.2,horizontal_flip = True) \n",
    "test_datagen = ImageDataGenerator (rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
    "classifier.fit_generator(training_set, steps_per_epoch = 8000, epochs = 25, validation_data = test_set, validation_steps = 2000)\n",
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image. load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims (test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67472816",
   "metadata": {},
   "source": [
    "# CNN project 2: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9321bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "filepath_dict = ('yelp':'yelp labelled.txt','amazon': 'amazon cells labelled.txt','imdb':'imdb_labelled. txt')\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items () :\n",
    "df = pd.read_csv (filepath, names=['sentence', 'label'], sep='\\t')\n",
    "df['source'] = source # Add another column filled with the sourc\n",
    "df_list.append(df)\n",
    "df = pd. concat(df_list)\n",
    "df_yelp = df[df['source'] == 'yelp']\n",
    "sentences = df_yelp ['sentence'].values\n",
    "y = df_yelp ['label'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
    "tokenizer = Tokenizer(num words=5000)\n",
    "tokenizer.fit_on_texts (sentences_train)\n",
    "X_train = tokenizer.texts_to_sequences (sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences (sentences_test)\n",
    "\\vocab_size = len (tokenizer.word_index) + 1\n",
    "# Adaing 1 because of reserved 0\n",
    "embedding_dim = 100\n",
    "maxlen = 100\n",
    "X_train = pad_sequences (X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences (X_test, padding= 'post', maxlen=maxlen)\n",
    "model = Sequential ()\n",
    "model. add (layers. Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model. add (layers. ConvID(128, 5, activation='relu'))\n",
    "model. add(layers.GlobalMaxPooling1D())\n",
    "model. add (layers. Dense(10, activation='relu'))\n",
    "model. add(layers. Dense(1, activation='sigmoid'))\n",
    "model.compile (optimizer='adam', loss= 'binary_crossentropy',metrics=['accuracy'])\n",
    "model. summary ()\n",
    "history = model.fit(X_train, y_train, epochs=10,verbose=False, validation_data=(X_test, y_test), batch_size=10)\n",
    "loss, accuracy = model.evaluate (X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate (X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy: {:.4f}\".format (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a8cdf",
   "metadata": {},
   "source": [
    "# Refrences: \n",
    "\n",
    "https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8\n",
    "\n",
    "https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22ddg\n",
    "\n",
    "https://github.com/venkateshtata/cnn_medium\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82c711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
